{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNAP Eligibility Estimation & Penetration Rate Calculation\n",
    "This part of the repository will be focused on the estimation of eligibility population in the Hennepin County across the tracts (the geographical units upon which the Census Bureau carries out surveys), races and ethics, and time.\n",
    "\n",
    "The main data sources used in this notebook consists of mainly two parts:\n",
    "1. The SNAP registration data generously provided by the Hennepin County, which is available in the repository: 'SNAP Summary data for LiveCase fall 2020.xlsx'.\n",
    "2. The survey data we use to estimate the total eligible people, which is provided by the Census API. You will find a full pipeline to obtain, transform, and adjust the data to arrive the estimations in this notebook.\n",
    "\n",
    "For the second part, we use in total of 3 data sources, all from census.gov: ACS5, ACS1, and CPS survey data. The reason for refering to different data sources is to make our estimation as accurate as possible. Otherwise the change in penetration rate will only depend on the change in registered people, which is not a good representation for performance and coverage.\n",
    "\n",
    "**ACS5** is a aggregation of 5 years of ACS1 data, providing detailed estimations on under-poverty line population across tracts and races. We use this data as a baseline. However, since the actual number of eligibility should be changing across each month due to lots of reasons (change in population base and the ratio of population under poverty line).\n",
    "\n",
    "**ACS1** is the data we use the reflect the change in the population base for each tract and race from year to year.\n",
    "\n",
    "**CPS** is a monthly timeseries survey data source and is perfect for adjustments to reflect the change in ratio of people under poverty (reflecting monthly fluctuations in the economy).\n",
    "\n",
    "We will first obtain the data one by one and use them to arrive the estimation of eligibility, and them use it to divide registration data to get the penetration data we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "from glob import glob\n",
    "import urllib\n",
    "import json\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "from matplotlib import pyplot as plt\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPS: Monthly Change in Eligible Rate\n",
    "(Need to download files, so might take some time)\n",
    "\n",
    "This section will download around 600 Mb of zip files for the CPS data from 2016 Jan to 2019 Dec. If you are using this notebook for later periods, please change the following lists.\n",
    "\n",
    "If you wish to skip downloading, please use the CPS output results in the repository: 'output/mn_cps_income_2016_2019.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "years = ['19', '18', '17', '16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Download'):\n",
    "    os.makedirs('Download') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading jan19... 1/48\n",
      "Complete!\n",
      "Downloading feb19... 2/48\n",
      "Complete!\n",
      "Downloading mar19... 3/48\n",
      "Complete!\n",
      "Downloading apr19... 4/48\n",
      "Complete!\n",
      "Downloading may19... 5/48\n",
      "Complete!\n",
      "Downloading jun19... 6/48\n",
      "Complete!\n",
      "Downloading jul19... 7/48\n",
      "Complete!\n",
      "Downloading aug19... 8/48\n",
      "Complete!\n",
      "Downloading sep19... 9/48\n",
      "Complete!\n",
      "Downloading oct19... 10/48\n",
      "Complete!\n",
      "Downloading nov19... 11/48\n",
      "Complete!\n",
      "Downloading dec19... 12/48\n",
      "Complete!\n",
      "Downloading jan18... 13/48\n",
      "Complete!\n",
      "Downloading feb18... 14/48\n",
      "Complete!\n",
      "Downloading mar18... 15/48\n",
      "Complete!\n",
      "Downloading apr18... 16/48\n",
      "Complete!\n",
      "Downloading may18... 17/48\n",
      "Complete!\n",
      "Downloading jun18... 18/48\n",
      "Complete!\n",
      "Downloading jul18... 19/48\n",
      "Complete!\n",
      "Downloading aug18... 20/48\n",
      "Complete!\n",
      "Downloading sep18... 21/48\n",
      "Complete!\n",
      "Downloading oct18... 22/48\n",
      "Complete!\n",
      "Downloading nov18... 23/48\n",
      "Complete!\n",
      "Downloading dec18... 24/48\n",
      "Complete!\n",
      "Downloading jan17... 25/48\n",
      "Complete!\n",
      "Downloading feb17... 26/48\n",
      "Complete!\n",
      "Downloading mar17... 27/48\n",
      "Complete!\n",
      "Downloading apr17... 28/48\n",
      "Complete!\n",
      "Downloading may17... 29/48\n",
      "Complete!\n",
      "Downloading jun17... 30/48\n",
      "Complete!\n",
      "Downloading jul17... 31/48\n",
      "Complete!\n",
      "Downloading aug17... 32/48\n",
      "Complete!\n",
      "Downloading sep17... 33/48\n",
      "Complete!\n",
      "Downloading oct17... 34/48\n",
      "Complete!\n",
      "Downloading nov17... 35/48\n",
      "Complete!\n",
      "Downloading dec17... 36/48\n",
      "Complete!\n",
      "Downloading jan16... 37/48\n",
      "Complete!\n",
      "Downloading feb16... 38/48\n",
      "Complete!\n",
      "Downloading mar16... 39/48\n",
      "Complete!\n",
      "Downloading apr16... 40/48\n",
      "Complete!\n",
      "Downloading may16... 41/48\n",
      "Complete!\n",
      "Downloading jun16... 42/48\n",
      "Complete!\n",
      "Downloading jul16... 43/48\n",
      "Complete!\n",
      "Downloading aug16... 44/48\n",
      "Complete!\n",
      "Downloading sep16... 45/48\n",
      "Complete!\n",
      "Downloading oct16... 46/48\n",
      "Complete!\n",
      "Downloading nov16... 47/48\n",
      "Complete!\n",
      "Downloading dec16... 48/48\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "url_head = 'https://www2.census.gov/programs-surveys/cps/datasets/20{1}/basic/{0}{1}pub.zip'\n",
    "download_path = 'Download/{0}{1}pub.zip'\n",
    "total = len(months) * len(years)\n",
    "current = 1\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        url = url_head.format(month, year)\n",
    "        download = download_path.format(month, year)\n",
    "        print('Downloading {}{}... {}/{}'.format(month, year, current, total))\n",
    "        if not os.path.exists(download):\n",
    "            urllib.request.urlretrieve(url, download)\n",
    "        print('Complete!')\n",
    "        current += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfiles = glob('Download/*pub.zip')\n",
    "\n",
    "for file in zipfiles:\n",
    "    with ZipFile(file, 'r') as z:\n",
    "        z.extractall('Download/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('Download/*.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CPS data is stored in an unusual structure where each field takes up a fixed position in each row. Here we only need five fields as shown below. You can find a full list of the avaliable fields in the [data dictionary](https://www2.census.gov/programs-surveys/cps/datasets/2020/basic/2020_Basic_CPS_Public_Use_Record_Layout_plus_IO_Code_list.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {'year':(17,21),\n",
    "             'month':(15,17),\n",
    "             'income':(38,40),\n",
    "             'family_count':(58,60),\n",
    "             'race':(138,140)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    tmp = pd.DataFrame([[line[var[0]:var[1]] for var in variables.values()] for line in \n",
    "                       open(file, 'r') if line[92:94] == '27'], columns=variables.keys())\n",
    "    df = pd.concat([df, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see disctionary\n",
    "race_map =  {'1': 'WhiteOnly',\n",
    "             '2': 'BlackOnly',\n",
    "             '3': 'AmericanIndian,AlaskanNativeOnly',\n",
    "             '4': 'AsianOnly',\n",
    "             '5': 'Hawaiian/PacificIslanderOnly',\n",
    "             '6': 'White-Black',\n",
    "             '7': 'White-AI',\n",
    "             '8': 'White-Asian',\n",
    "             '9': 'White-HP',\n",
    "             '10': 'Black-AI',\n",
    "             '11': 'Black-Asian',\n",
    "             '12': 'Black-HP',\n",
    "             '13': 'AI-Asian',\n",
    "             '14': 'AI-HP',\n",
    "             '15': 'Asian-HP',\n",
    "             '16': 'W-B-AI',\n",
    "             '17': 'W-B-A',\n",
    "             '18': 'W-B-HP',\n",
    "             '19': 'W-AI-A',\n",
    "             '20': 'W-AI-HP',\n",
    "             '21': 'W-A-HP',\n",
    "             '22': 'B-AI-A',\n",
    "             '23': 'W-B-AI-A',\n",
    "             '24': 'W-AI-A-HP',\n",
    "             '25': 'Other3RaceCombinations',\n",
    "             '26': 'Other4and5RaceCombinations',\n",
    "             '-1': np.nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = df['race'].str.replace(' ','').map(race_map)\n",
    "\n",
    "df[['year', 'month', 'income', 'family_count']] =\\\n",
    "df[['year', 'month', 'income', 'family_count']].astype(int)\n",
    "\n",
    "# exclude the households with unknown income\n",
    "df = df[df['income']!=-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eligibility criteria for SNAP gross income limits.\n",
    "\n",
    "See website: https://www.fns.usda.gov/snap/recipient/eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_mapping =  {1: 16596,\n",
    "                     2: 22416,\n",
    "                     3: 28236,\n",
    "                     4: 34068,\n",
    "                     5: 39888,\n",
    "                     6: 45708,\n",
    "                     7: 51540,\n",
    "                     8: 57360}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The income field in the CPS data only provides an income range for each household (see dictionary). For estimation purpose, we use the mid-point of each range to compare with the SNAP criteria. We also checked the robustness in this treatment and found no significant difference in the final results whether using lower bound, mid-point, or higher bound for estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher Range\n",
    "# income_mapping ={1: 5000,\n",
    "#                  2: 7500,\n",
    "#                  3: 10000,\n",
    "#                  4: 12500,\n",
    "#                  5: 15000,\n",
    "#                  6: 20000,\n",
    "#                  7: 25000,\n",
    "#                  8: 30000,\n",
    "#                  9: 35000,\n",
    "#                  10: 40000,\n",
    "#                  11: 50000,\n",
    "#                  12: 60000,\n",
    "#                  13: 75000,\n",
    "#                  14: 100000,\n",
    "#                  15: 150000,\n",
    "#                  16: np.inf}\n",
    "# Lower Range\n",
    "# income_mapping ={1: 0,\n",
    "#                  2: 7500,\n",
    "#                  3: 7500,\n",
    "#                  4: 10000,\n",
    "#                  5: 12500,\n",
    "#                  6: 15000,\n",
    "#                  7: 20000,\n",
    "#                  8: 25000,\n",
    "#                  9: 30000,\n",
    "#                  10: 35000,\n",
    "#                  11: 40000,\n",
    "#                  12: 50000,\n",
    "#                  13: 60000,\n",
    "#                  14: 75000,\n",
    "#                  15: 100000,\n",
    "#                  16: 150000}\n",
    "# Middle Range\n",
    "income_mapping ={1: 5000,\n",
    "                 2: 6750,\n",
    "                 3: 8750,\n",
    "                 4: 11250,\n",
    "                 5: 13750,\n",
    "                 6: 17500,\n",
    "                 7: 22500,\n",
    "                 8: 27500,\n",
    "                 9: 32500,\n",
    "                 10: 37500,\n",
    "                 11: 45000,\n",
    "                 12: 55000,\n",
    "                 13: 67500,\n",
    "                 14: 87500,\n",
    "                 15: 125000,\n",
    "                 16: np.inf}\n",
    "def is_eligible(family_count, income_level, eligible_mapping, income_mapping):\n",
    "    if family_count <= 8:\n",
    "        threshold = eligible_mapping[family_count]\n",
    "    else:\n",
    "        threshold = 486 * (family_count-8) + 57360\n",
    "    income = income_mapping[income_level]\n",
    "    if income > threshold:\n",
    "        eligible = False\n",
    "    else:\n",
    "        eligible = True\n",
    "    \n",
    "    return eligible  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eligible'] = df.apply(lambda x: is_eligible(x['family_count'], x['income'], \n",
    "                                                eligible_mapping, income_mapping), axis=1)\n",
    "\n",
    "df['eligible_count'] = df['family_count'] * df['eligible']\n",
    "\n",
    "df.to_csv('output/mn_cps_income_2016_2019.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please Start from here if you would like to skip the downloading part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output/mn_cps_income_2016_2019.csv')\n",
    "cps = df.groupby(['year', 'month'])[['family_count', 'eligible_count']].sum().reset_index()\n",
    "cps['cps_poverty_ratio'] = cps['eligible_count'] / cps['family_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>family_count</th>\n",
       "      <th>eligible_count</th>\n",
       "      <th>cps_poverty_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5289</td>\n",
       "      <td>1068</td>\n",
       "      <td>0.201929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>5549</td>\n",
       "      <td>1107</td>\n",
       "      <td>0.199495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>5327</td>\n",
       "      <td>911</td>\n",
       "      <td>0.171016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>5325</td>\n",
       "      <td>1033</td>\n",
       "      <td>0.193991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>5068</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.220994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  family_count  eligible_count  cps_poverty_ratio\n",
       "0  2016      1          5289            1068           0.201929\n",
       "1  2016      2          5549            1107           0.199495\n",
       "2  2016      3          5327             911           0.171016\n",
       "3  2016      4          5325            1033           0.193991\n",
       "4  2016      5          5068            1120           0.220994"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps.to_csv('output/mn_cps_eligibility_by_month.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACS1: Yearly Change in Population by Race\n",
    "The ACS data API takes a very different structure. Please check the [api variables page](https://api.census.gov/data/2018/acs/acs1/subject/variables.html) for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for year in range(2016,2020):\n",
    "    url = 'https://api.census.gov/data/{}/acs/acs1/?get=B03002_001E,B03002_003E,'.format(year)+\\\n",
    "    'B03002_004E,B03002_005E,B03002_006E,B03002_007E,B03002_008E,B03002_009E,B03002_012E&for=county:*'+\\\n",
    "    '&in=state:27'\n",
    "\n",
    "    col_names = ['Total', 'White Alone, Not Hispanic or Latino', 'Black or African American Alone', \n",
    "                 'American Indian and Alaska Native Alone', 'Asian Alone', \n",
    "                 'Native Hawaiian and Other Pacific Islander Alone', 'Some Other Race Alone',\n",
    "                 'Two or More Races', 'Hispanic or Latino', 'state', 'county']\n",
    "\n",
    "    with urllib.request.urlopen(url) as r:\n",
    "        tmp = pd.DataFrame(json.loads(r.read())[1:], columns=col_names)\n",
    "        \n",
    "    tmp = tmp[tmp['county']=='053']\n",
    "    tmp = tmp.astype(int)\n",
    "    tmp['year'] = year\n",
    "    df = pd.concat([df,tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.melt(df, 'year', \n",
    "                     ['White Alone, Not Hispanic or Latino', 'Black or African American Alone',\n",
    "                      'American Indian and Alaska Native Alone', 'Asian Alone',\n",
    "                      'Native Hawaiian and Other Pacific Islander Alone', 'Some Other Race Alone',\n",
    "                      'Two or More Races', 'Hispanic or Latino'], \n",
    "                     'Race_Ethnicity', 'county_population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Race_Ethnicity</th>\n",
       "      <th>county_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>White</td>\n",
       "      <td>855894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>White</td>\n",
       "      <td>860662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>White</td>\n",
       "      <td>860981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>White</td>\n",
       "      <td>863985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>Black/African American</td>\n",
       "      <td>156239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year          Race_Ethnicity  county_population\n",
       "0  2016                   White             855894\n",
       "1  2017                   White             860662\n",
       "2  2018                   White             860981\n",
       "3  2019                   White             863985\n",
       "4  2016  Black/African American             156239"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Race_Ethnicity_Mapping = {'Black or African American Alone':'Black/African American',\n",
    "                          'American Indian and Alaska Native Alone':'American Indian or Alaskan Native',\n",
    "                          'Asian Alone':'Asian/Pacific Islander',\n",
    "                          'Native Hawaiian and Other Pacific Islander Alone':'Asian/Pacific Islander',\n",
    "                          'Some Other Race Alone':'Other or Unknown',\n",
    "                          'Two or More Races':'Other or Unknown',\n",
    "                          'White Alone, Not Hispanic or Latino':'White',\n",
    "                          'Hispanic or Latino':'Hispanic or Latino'}\n",
    "population['Race_Ethnicity'] = population['Race_Ethnicity'].map(Race_Ethnicity_Mapping)\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.to_csv('output/acs1_population_by_race.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Above Data to Adjusting ACS5, the Baseline\n",
    "\n",
    "There are in total three steps of adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty = pd.read_csv('output/tract_poverty_data_acs5_2018.csv',dtype={'tract':str})\n",
    "poverty = poverty[poverty['Race_Ethnicity']!='Total Population'][['tract', 'Total', 'Below_Poverty_Count', 'Race_Ethnicity']]\n",
    "poverty = poverty[poverty['Total']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty['Race_Ethnicity'] = poverty['Race_Ethnicity'].map(Race_Ethnicity_Mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 100 Percent to 125 Percent Adjustment\n",
    "\n",
    "Population under poverty line provided by ACS5 are not exactly matching the SNAP criteria of gorss income under 130% of poverty line. So the first step is to adjust it to the 125% of poverty line (best approximation we can get from the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.census.gov/data/2018/acs/acs5/subject?get=NAME,S1701_C01_039E,S1701_C02_001E' +\\\n",
    "      '&for=tract:*&in=state:27&in=county:053'\n",
    "\n",
    "col_names = ['Name', '125%_poverty', '100%_poverty', 'state','county','tract']\n",
    "\n",
    "with urllib.request.urlopen(url) as r:\n",
    "    df = pd.DataFrame(json.loads(r.read())[1:], columns=col_names)\n",
    "\n",
    "df[['125%_poverty', '100%_poverty']] = df[['125%_poverty', '100%_poverty']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty = pd.merge(poverty, df[['tract', '125%_poverty', '100%_poverty']], on='tract')\n",
    "\n",
    "poverty['below_125%_estimate'] = poverty['Below_Poverty_Count'] * (poverty['125%_poverty']/poverty['100%_poverty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Total Population Adjust by Year (Use ACS1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('output/acs1_population_by_race.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "population['merge'] = 1\n",
    "poverty['merge'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_adjust = pd.merge(poverty, population, how='outer', on=['merge','Race_Ethnicity'])\n",
    "\n",
    "poverty_adjust['acs5_county_population'] = poverty_adjust.groupby(['year','Race_Ethnicity'])['Total'].transform(sum)\n",
    "\n",
    "poverty_adjust['below_125%_estimate'] = poverty_adjust['below_125%_estimate'] * poverty_adjust['county_population'] / poverty_adjust['acs5_county_population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adjust Poverty Ratio Over Time (use CPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_poverty_ratio = poverty_adjust['below_125%_estimate'].sum() / poverty_adjust['Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12157282751665367"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall eligible rate in Hennepin County\n",
    "# We will try to use CPS data to make it reflect the changes across time\n",
    "acs_poverty_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_adjust['poverty_ratio'] = poverty_adjust['below_125%_estimate'] / poverty_adjust['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps = pd.read_csv('output/mn_cps_eligibility_by_month.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps['merge'] = 1\n",
    "poverty_adjust['merge'] = 1\n",
    "poverty_adjust = pd.merge(cps[['year', 'month', 'cps_poverty_ratio', 'merge']], \n",
    "                          poverty_adjust[['tract', 'Race_Ethnicity', 'below_125%_estimate', 'poverty_ratio', 'merge']], \n",
    "                          on='merge').drop('merge', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_adjust['poverty_ratio_adj'] = poverty_adjust['poverty_ratio'] * (poverty_adjust['cps_poverty_ratio'] / acs_poverty_ratio)\n",
    "\n",
    "poverty_adjust.loc[poverty_adjust['poverty_ratio_adj']>1, 'poverty_ratio_adj'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimated Eligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_adjust['Estimated Eligible'] = (poverty_adjust['poverty_ratio_adj'] * poverty_adjust['below_125%_estimate']).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_eligible = poverty_adjust[['year','month','tract','Race_Ethnicity','Estimated Eligible']]\n",
    "\n",
    "estimated_eligible.to_csv('output/estimated_eligible.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine with Registration Data to Calculate Penetration Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap = pd.read_excel('SNAP Summary data for LiveCase fall 2020.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap['elig_month'] = pd.to_datetime(snap['elig_month'])\n",
    "snap['tract'] = snap['tract'].astype(str)\n",
    "\n",
    "snap = snap[snap['tract'].str[2:5]=='053'].rename(columns={'race_ethnicity':'Race_Ethnicity'})\n",
    "\n",
    "snap['tract'] = snap['tract'].str[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-a4fde5035445>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  estimated_eligible['elig_month'] = pd.to_datetime(estimated_eligible['year'].astype(str)+'-'+estimated_eligible['month'].astype(str)+'-1')\n"
     ]
    }
   ],
   "source": [
    "estimated_eligible['elig_month'] = pd.to_datetime(estimated_eligible['year'].astype(str)+'-'+estimated_eligible['month'].astype(str)+'-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap = pd.merge(estimated_eligible[['elig_month', 'tract', 'Race_Ethnicity', 'Estimated Eligible']], \n",
    "         snap, how='left', on=['elig_month', 'tract', 'Race_Ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap['people'] = snap['people'].fillna(0)\n",
    "snap['coverage'] = snap['people'] / snap['Estimated Eligible']\n",
    "snap.loc[snap['coverage']==np.inf, 'coverage'] = np.nan\n",
    "# cap the rate to 100%\n",
    "snap.loc[snap['coverage']>1, 'coverage'] = 1\n",
    "\n",
    "snap.to_csv('output/results.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
